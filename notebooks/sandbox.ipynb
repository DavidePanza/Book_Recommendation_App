{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaf2039",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918695b7",
   "metadata": {},
   "source": [
    "You can perform a volumes search by sending an HTTP GET request to the following URI:\n",
    "\n",
    "\n",
    "https://www.googleapis.com/books/v1/volumes?q=search+terms\n",
    "This request has a single required parameter:\n",
    "\n",
    "q - Search for volumes that contain this text string. There are special keywords you can specify in the search terms to search in particular fields, such as:\n",
    "- intitle: Returns results where the text following this keyword is found in the title.\n",
    "- inauthor: Returns results where the text following this keyword is found in the author.\n",
    "- inpublisher: Returns results where the text following this keyword is found in the publisher.\n",
    "- subject: Returns results where the text following this keyword is listed in the category list of the volume.\n",
    "- isbn: Returns results where the text following this keyword is the ISBN number.\n",
    "- lccn: Returns results where the text following this keyword is the Library of Congress Control Number.\n",
    "- oclc: Returns results where the text following this keyword is the Online Computer Library Center number.\n",
    "\n",
    "### Request\n",
    "Here is an example of searching for Daniel Keyes' \"Flowers for Algernon\":\n",
    "\n",
    "\n",
    "GET https://www.googleapis.com/books/v1/volumes?q=flowers+inauthor:keyes&key=yourAPIKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fda06",
   "metadata": {},
   "source": [
    "## Get Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the search parameters\n",
    "category = 'fiction'\n",
    "start_index = 0\n",
    "max_results = 100000 \n",
    "\n",
    "# API URL\n",
    "url = f\"https://openlibrary.org/search.json?q=subject:{category}&start={start_index}&limit={max_results}&fields=author_name\"\n",
    "\n",
    "# Send the GET request\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "authors = []\n",
    "\n",
    "# Check if 'docs' is in the response\n",
    "if 'docs' in data:\n",
    "    # Print the total number of books found\n",
    "    print(f\"Total books found: {data['num_found']}\")\n",
    "    \n",
    "    # Iterate through the books and print their details\n",
    "    for idx, book in enumerate(data['docs']):\n",
    "        author = book.get('author_name', ['No author available'])\n",
    "        if len(author) == 1:\n",
    "            authors.append(author[0])\n",
    "        else:\n",
    "            pass\n",
    "else:\n",
    "    print(\"No books found or 'docs' key is missing in the response.\")\n",
    "\n",
    "# Filter out duplicate authors\n",
    "authors_filtered = set(authors)\n",
    "\n",
    "# Store the filtered authors in a text file\n",
    "data_path = \"../data/authors_filtered.txt\"\n",
    "with open(data_path, 'w') as f:\n",
    "    for author in authors_filtered:\n",
    "        f.write(f\"{author}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c9170",
   "metadata": {},
   "source": [
    "## Scraping Google Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0fa529d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"AIzaSyDSSplnRCPbL_k_ukQovrz6-lOH94RA13U\"\n",
    "# https://developers.google.com/books/docs/v1/using#APIKey\n",
    "\n",
    "authors_path = \"../data/authors_filtered.txt\"\n",
    "with open(authors_path, 'r') as f:\n",
    "    authors = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "985dcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setting_api_params(author, start_index=0, language='en', country='US', max_results=40):\n",
    "    params = {\n",
    "        'q': f'inauthor:{author}',\n",
    "        'startIndex': start_index,\n",
    "        'langRestrict': language,\n",
    "        'country': country,\n",
    "        'maxResults': max_results,\n",
    "        'printType': 'books',\n",
    "        'fields': '''totalItems,items(\n",
    "                kind,id,etag,selfLink,\n",
    "                volumeInfo(\n",
    "                    title,subtitle,authors,publisher,publishedDate,description,\n",
    "                    pageCount,printType,mainCategory,categories,averageRating,\n",
    "                    ratingsCount,language,previewLink,infoLink,canonicalVolumeLink,\n",
    "                    imageLinks(smallThumbnail,thumbnail)\n",
    "                ),\n",
    "                saleInfo(\n",
    "                    country,saleability,\n",
    "                    listPrice(amount,currencyCode),\n",
    "                    retailPrice(amount,currencyCode),\n",
    "                    buyLink\n",
    "                )\n",
    "                    )'''.replace('\\n', '').replace(' ', ''),\n",
    "                    'key': API_KEY,\n",
    "            }\n",
    "    \n",
    "    return params\n",
    "\n",
    "def get_books(author, start_index=0):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes\"\n",
    "    params = setting_api_params(author, start_index)\n",
    "    response = requests.get(url, params=params)\n",
    "    books = response.json().get('items', [])\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_overlap(text1, text2, word_threshold=5):\n",
    "    \"\"\"\n",
    "    Calculate what percentage of text1 appears in text2 using sliding window approach.\n",
    "    \"\"\"\n",
    "    words1 = text1.lower().split()\n",
    "    words2_text = ' '.join(text2.lower().split())\n",
    "    \n",
    "    if len(words1) < word_threshold:\n",
    "        return 0.0\n",
    "    \n",
    "    matches = 0\n",
    "    i = 0\n",
    "    while i <= len(words1) - word_threshold:\n",
    "        window = ' '.join(words1[i:i + word_threshold])\n",
    "        if window in words2_text:\n",
    "            matches += word_threshold\n",
    "            i += word_threshold  # Skip ahead properly\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    return min(matches / len(words1), 1.0)  # Cap at 100%\n",
    "\n",
    "def find_similar_descriptions(books, similarity_threshold=0.8, min_description_length=50):\n",
    "    \"\"\"\n",
    "    Find books with descriptions where 80%+ of text appears in another description.\n",
    "    Returns indices of books to remove.\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    # Extract descriptions and track valid indices\n",
    "    for idx, book in enumerate(books):\n",
    "        desc = book.get('volumeInfo', {}).get('description', '').strip()\n",
    "        if len(desc) >= min_description_length:\n",
    "            descriptions.append(desc)\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    to_remove = set()\n",
    "    \n",
    "    for i, desc1 in enumerate(descriptions):\n",
    "        if valid_indices[i] in to_remove:\n",
    "            continue\n",
    "            \n",
    "        for j, desc2 in enumerate(descriptions):\n",
    "            if i != j and valid_indices[j] not in to_remove:\n",
    "                # Check if desc1 is mostly contained in desc2\n",
    "                overlap1_in_2 = calculate_text_overlap(desc1, desc2)\n",
    "                overlap2_in_1 = calculate_text_overlap(desc2, desc1)\n",
    "                \n",
    "                if overlap1_in_2 >= similarity_threshold or overlap2_in_1 >= similarity_threshold:\n",
    "                    # High overlap detected - remove both books\n",
    "                    max_overlap = max(overlap1_in_2, overlap2_in_1)\n",
    "                    to_remove.add(valid_indices[i])\n",
    "                    to_remove.add(valid_indices[j])\n",
    "                    print(f\"Removing both books {valid_indices[i]} and {valid_indices[j]}: {max_overlap:.1%} overlap\")\n",
    "                    break\n",
    "    \n",
    "    return list(to_remove)\n",
    "\n",
    "def deduplicate_by_description_similarity(books, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Remove books with highly similar descriptions.\n",
    "    \"\"\"\n",
    "    indices_to_remove = find_similar_descriptions(books, similarity_threshold)\n",
    "    return [book for idx, book in enumerate(books) if idx not in indices_to_remove]\n",
    "\n",
    "def enhanced_deduplicate_books(books, verbose=False):\n",
    "    \"\"\"\n",
    "    Enhanced deduplication combining title and description similarity.\n",
    "    \"\"\"\n",
    "    # First deduplicate by titles\n",
    "    books = deduplicate_books_by_shortest_title(books, verbose)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nAfter title deduplication: {len(books)} books\")\n",
    "    \n",
    "    # Then deduplicate by description similarity\n",
    "    books = deduplicate_by_description_similarity(books, similarity_threshold=0.8)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"After description deduplication: {len(books)} books\")\n",
    "    \n",
    "    return books\n",
    "\n",
    "# Modified version of your existing function\n",
    "def deduplicate_books_by_shortest_title(books, verbose=False):\n",
    "    \"\"\"\n",
    "    Deduplicate books by their shortest title.\n",
    "    \"\"\"\n",
    "    titles = [book['volumeInfo'].get('title', '').strip().lower() for book in books]\n",
    "\n",
    "    to_remove = []\n",
    "    for idx_outer, title in enumerate(titles):\n",
    "        if idx_outer in to_remove:\n",
    "            continue\n",
    "        # this checks for duplicates and skips if none found\n",
    "        temp_no_outer = titles[:idx_outer] + titles[idx_outer+1:]\n",
    "        if any(title in temp_no_outer[idx_temp] for idx_temp in range(len(temp_no_outer))):\n",
    "            if verbose:\n",
    "                print(f'Duplicate found: {title}')\n",
    "            for idx_inner in range(len(titles)):\n",
    "                if idx_inner == idx_outer:\n",
    "                    continue\n",
    "                if titles[idx_outer] in titles[idx_inner]:\n",
    "                    if verbose:\n",
    "                        print(f'  \"{titles[idx_inner]}\" contains \"{titles[idx_outer]}\"')\n",
    "                    if ((len(titles[idx_outer]) < len(titles[idx_inner])) and (len(titles[idx_outer]) > 3)) or (len(titles[idx_outer]) == len(titles[idx_inner])):\n",
    "                        to_remove.append(idx_inner)\n",
    "                        continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('No duplicate found')\n",
    "\n",
    "    return [books[idx] for idx in range(len(books)) if idx not in to_remove]\n",
    "\n",
    "def get_filtered_books(author, iterations=3):\n",
    "    \"\"\"\n",
    "    Get a list of filtered book IDs for a specific author with enhanced deduplication.\n",
    "    \"\"\"\n",
    "    # total items is unreliable, using an euristic of 3 iterations to gather more results per author\n",
    "    iteration = 0\n",
    "    filtered_books = []\n",
    "    while iteration < iterations:\n",
    "        print(f\"Fetching books for {author}, iteration {iteration + 1}\")\n",
    "        url = f\"https://www.googleapis.com/books/v1/volumes\"\n",
    "        params = setting_api_params(author, start_index=iteration * 40)\n",
    "        response = requests.get(url, params=params)\n",
    "        books = response.json().get('items', [])\n",
    "        \n",
    "        # Get the current iteration length\n",
    "        current_iteration_length = len(books)\n",
    "\n",
    "        # Filter books\n",
    "        books[:] = [book for book in books if \n",
    "                    book['volumeInfo'].get('authors', []) == [\"Stephen King\"]\n",
    "                    and book['volumeInfo'].get('language', '') == 'en'\n",
    "                    and book['volumeInfo'].get('title', '') != ''\n",
    "                    and len(book['volumeInfo'].get('description', '')) > 100\n",
    "                    and book['id']\n",
    "                    ]\n",
    "        \n",
    "        filtered_books.extend(books)\n",
    "\n",
    "        if current_iteration_length < 40:\n",
    "            break\n",
    "        iteration += 1\n",
    "\n",
    "    # Enhanced deduplication after all iterations\n",
    "    return enhanced_deduplicate_books(filtered_books, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "4d05ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching books for Stephen King, iteration 1\n",
      "Fetching books for Stephen King, iteration 2\n",
      "Fetching books for Stephen King, iteration 3\n",
      "Fetching books for Stephen King, iteration 4\n",
      "Fetching books for Stephen King, iteration 5\n",
      "Fetching books for Stephen King, iteration 6\n"
     ]
    }
   ],
   "source": [
    "books = get_filtered_books(\"Stephen King\", 10)\n",
    "descriptions = [book['volumeInfo'].get('description', '').strip().lower() for book in books]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ff28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
